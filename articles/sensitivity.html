<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="COINr">
<title>Sensitivity Analysis • COINr</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.3/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.3/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Sensitivity Analysis">
<meta property="og:description" content="COINr">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">COINr</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.1.1</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../articles/overview.html">Overview</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../articles/v1.html">v1.0 updates</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <h6 class="dropdown-header" data-toc-skip>Construction</h6>
    <a class="dropdown-item" href="../articles/coins.html">Building coins</a>
    <a class="dropdown-item" href="../articles/imputation.html">Imputation of missing data</a>
    <a class="dropdown-item" href="../articles/denomination.html">Denomination</a>
    <a class="dropdown-item" href="../articles/screening.html">Unit screening</a>
    <a class="dropdown-item" href="../articles/treat.html">Outlier treatment</a>
    <a class="dropdown-item" href="../articles/normalise.html">Normalisation</a>
    <a class="dropdown-item" href="../articles/weights.html">Weighting</a>
    <a class="dropdown-item" href="../articles/aggregate.html">Aggregation</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Post-processing</h6>
    <a class="dropdown-item" href="../articles/visualisation.html">Visualisation</a>
    <a class="dropdown-item" href="../articles/analysis.html">Statistical analysis</a>
    <a class="dropdown-item" href="../articles/results.html">Presenting results</a>
    <a class="dropdown-item" href="../articles/adjustments.html">Adjustments and comparisons</a>
    <a class="dropdown-item" href="../articles/sensitivity.html">Sensitivity analysis</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Other</h6>
    <a class="dropdown-item" href="../articles/data_selection.html">Data selection</a>
    <a class="dropdown-item" href="../articles/other_functions.html">Other functions</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Functions</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/bluefoxr/COINr/">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Sensitivity Analysis</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/bluefoxr/COINr/blob/HEAD/vignettes/sensitivity.Rmd" class="external-link"><code>vignettes/sensitivity.Rmd</code></a></small>
      <div class="d-none name"><code>sensitivity.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Sensitivity analysis is often confused with <em>uncertainty
analysis</em>. Uncertainty analysis involves estimating the uncertainty
in the outputs of a system (here, the scores and ranks of the composite
indicator), given the uncertainties in the inputs (here, methodological
decisions, weights, etc.). The results of an uncertainty include for
example confidence intervals over the ranks, median ranks, and so
on.</p>
<p>Sensitivity analysis is an extra step after uncertainty analysis, and
estimates which of the input uncertainties are driving the output
uncertainty, and by how much. A rule of thumb, known as the <a href="https://en.wikipedia.org/wiki/Pareto_principle" class="external-link">Pareto
Principle</a> (or the 80/20 Rule) suggests that often, only a small
proportion of the input uncertainties are causing the majority of the
output uncertainty. Sensitivity analysis allows us to find which input
uncertainties are significant (and therefore perhaps worthy of extra
attention), and which are not important.</p>
<p>In reality, sensitivity analysis and uncertainty analysis can be
performed simultaneously. However in both cases, the main technique is
to use Monte Carlo methods. This essentially involves re-calculating the
composite indicator many times, each time randomly varying the uncertain
variables (assumptions, parameters), in order to estimate the output
distributions.</p>
<p>COINr implements a flexible variance-based global sensitivity
analysis approach, which allows almost any assumption to be varied, as
long as the distribution of alternative values can be described.
Variance-based “sensitivity indices” are estimated using a Monte Carlo
design (running the composite indicator many times with a particular
combination of input values). This follows the methodology described in
<a href="https://doi.org/10.1111/j.1467-985X.2005.00350.x" class="external-link">this
paper</a>.</p>
</div>
<div class="section level2">
<h2 id="defining-the-problem">Defining the problem<a class="anchor" aria-label="anchor" href="#defining-the-problem"></a>
</h2>
<p>The first step in a sensitivity analysis is to identify
<em>which</em> assumptions to treat as uncertain, and <em>what</em>
alternative values to assign to each assumption. Let’s begin with the
“which”: think about all the ingredients that have gone into making the
composite indicator: the data itself, the selection of indicators, and
the methodological decisions along the way (which imputation method to
use, if any; whether to treat outliers and in what way, which
normalisation method, etc…). We cannot test everything, but we can pick
a few assumptions that seem important, and where we have plausible
alternatives that we could assign.</p>
<p>Here we will work with the familiar in-built example coin. You can
see exactly how this is built by calling
<code>edit(build_example_coin)</code> by the way.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://bluefoxr.github.io/COINr/">COINr</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># build example coin</span></span>
<span><span class="va">coin</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/build_example_coin.html">build_example_coin</a></span><span class="op">(</span>quietly <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p>We will test four assumptions:</p>
<ol style="list-style-type: decimal">
<li>The maximum number of Winsorised data points. This is currently set
at five, but we will let it vary between 1 and 5 points.</li>
<li>The normalisation method. By default the min-max method is used, but
we will also consider the z-score as an alternative.</li>
<li>The weights. We will test perturbing the weights randomly inside a
set interval.</li>
<li>The aggregation method. The example uses the arithmetic mean but we
will also consider the geometric mean as an alternative.</li>
</ol>
</div>
<div class="section level2">
<h2 id="input-distributions">Input distributions<a class="anchor" aria-label="anchor" href="#input-distributions"></a>
</h2>
<p>Having now selected <em>which</em> assumptions to vary, we can now
work on defining the distributions for each assumption. Sensitivity
analysis is a probabilistic tool, so each input assumption is treated as
a random variable, which means we have to define a distribution for each
assumption.</p>
<p>The function to run a sensitivity in COINr is called
<code><a href="../reference/get_sensitivity.html">get_sensitivity()</a></code>. It takes a little understanding to get
this set up properly. The argument that defines the input distributions
is a list called <code>SA_specs</code>. This specifies which assumptions
to vary, the distributions for each assumption, and where each
assumption can be found in the coin. Let’s demonstrate by defining one
part of <code>SA_specs</code>, for our first assumption: the maximum
number of Winsorised points.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># component of SA_specs for winmax distribution</span></span>
<span><span class="va">l_winmax</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>Address <span class="op">=</span> <span class="st">"$Log$Treat$global_specs$f1_para$winmax"</span>,</span>
<span>               Distribution <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">5</span>,</span>
<span>               Type <span class="op">=</span> <span class="st">"discrete"</span><span class="op">)</span></span></code></pre></div>
<p>Each uncertain assumption is defined by a list with three components.
The “Address” component describes <em>where</em> in the coin the object
of interest is found. You should look inside the coin to find this:
notice that you don’t specify the name of the coin itself, i.e. it is
not <code>coin$Log$Treat$...</code> but rather just
<code>$Log$Treat$...</code>.</p>
<p>Next is the “Distribution”, which essentially describes the
alternatives for the parameter. Here we have entered <code>1:5</code>,
i.e. any integer between 1 and 5. Finally the “Type” entry should be set
to either “discrete” or “continuous”. In the former, the distribution is
assumed to be discrete, so that samples are taken from the alternatives
given in “Distribution”. In the latter, the distribution is assumed to
be continuous and uniform, and “Distribution” should be a 2-length
vector specifying the upper and lower bounds of the parameter. Obviously
in this latter case, the parameter must be numeric, and must be able to
take non-integer values.</p>
<p>In summary, the list above specifies that the winmax parameter should
be allowed to vary between 1 and 5 (integers). This list will be
combined with lists for the other assumptions below, and input to
<code><a href="../reference/get_sensitivity.html">get_sensitivity()</a></code>.</p>
<p>Now let’s see the entry for the normalisation method:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># normalisation method</span></span>
<span></span>
<span><span class="co"># first, we define the two alternatives: minmax or zscore (along with respective parameters)</span></span>
<span><span class="va">norm_alts</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>f_n <span class="op">=</span> <span class="st">"n_minmax"</span>, f_n_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">100</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>f_n <span class="op">=</span> <span class="st">"n_zscore"</span>, f_n_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">10</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># now put this in a list</span></span>
<span><span class="va">l_norm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>Address <span class="op">=</span> <span class="st">"$Log$Normalise$global_specs"</span>,</span>
<span>               Distribution <span class="op">=</span> <span class="va">norm_alts</span>,</span>
<span>               Type <span class="op">=</span> <span class="st">"discrete"</span><span class="op">)</span></span></code></pre></div>
<p>This is a bit more complicated because when we switch between the
min-max and z-score methods, we also want to use the corresponding set
of parameters (<code>f_n_para</code>). That means that the parameter to
target is the entire “global_specs” argument of
<code><a href="../reference/Normalise.html">Normalise()</a></code>. We define two alternatives: one with min-max
between 1 and 100, and the other being z-score with mean 10 and standard
deviation 2. Notice that you need to be careful to wrap things
appropriately in lists as required by each function.</p>
<p>Otherwise the rest is straight forward: we define the address and
attach the <code>norm_alts</code> alternatives to the main list chunk.
The distribution is discrete. Notice that each specification includes
the “default” value of the assumption, not just the alternative(s).</p>
<p>Next is the weights, and this is also a special case. There are
different ways we could approach changing the weights. First, we might
have a small number of alternative weight sets, perhaps one is the
original weights, one is from PCA, and one has been adjusted by hand. In
that case, we could put these three sets of weights in a list and set
the address to <code>$Log$Aggregate$w</code>, as a discrete
distribution.</p>
<p>A second possibility would be to treat individual weights as
individual parameters. This might be a good idea if we only want to vary
a small number of individual weights, e.g. the sub-index weights (of
which there are two). Then we could define one assumption for one weight
and set the address as
e.g. <code>coin$Meta$Weights$Original$Weight[58]</code> which is the
location of the “Conn” sub-index weight, and similarly for the “Sust”
sub-index. We would then set <code>Type = "continuous"</code> and set
the upper and lower bounds as needed, e.g. <code>c(0.5, 1)</code> to
vary between 0.5 and 1.</p>
<p>To instead get an overall perturbation of weights, we have to use a
helper function. The <code><a href="../reference/get_noisy_weights.html">get_noisy_weights()</a></code> function is
designed for this purpose: it generates replications of your set of
weights, where each replication has some random noise added to it
according to your specifications. Here is how it works. You take your
nominal weights (those that you would normally use) and feed them into
the function:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># get nominal weights</span></span>
<span><span class="va">w_nom</span> <span class="op">&lt;-</span> <span class="va">coin</span><span class="op">$</span><span class="va">Meta</span><span class="op">$</span><span class="va">Weights</span><span class="op">$</span><span class="va">Original</span></span>
<span></span>
<span><span class="co"># build data frame specifying the levels to apply the noise at</span></span>
<span><span class="va">noise_specs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>Level <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">3</span><span class="op">)</span>,</span>
<span>                         NoiseFactor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.25</span>, <span class="fl">0.25</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># get 100 replications</span></span>
<span><span class="va">noisy_wts</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_noisy_weights.html">get_noisy_weights</a></span><span class="op">(</span>w <span class="op">=</span> <span class="va">w_nom</span>, noise_specs <span class="op">=</span> <span class="va">noise_specs</span>, Nrep <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># examine one of the noisy weight sets</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">tail</a></span><span class="op">(</span><span class="va">noisy_wts</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt;       iCode Level    Weight</span></span>
<span><span class="co">#&gt; 55  Environ     2 0.7784529</span></span>
<span><span class="co">#&gt; 56   Social     2 1.2277917</span></span>
<span><span class="co">#&gt; 57 SusEcFin     2 0.8565050</span></span>
<span><span class="co">#&gt; 58     Conn     3 0.9726575</span></span>
<span><span class="co">#&gt; 59     Sust     3 1.0950523</span></span>
<span><span class="co">#&gt; 60    Index     4 1.0000000</span></span></code></pre></div>
<p>The <code>noisy_wts</code> object is a list containing 100 data
frames, each of which is a set of weights with slightly different
values. The sample above shows the last few rows of one of these
weight-sets.</p>
<p>Now we can feed this into our list chunk:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># component of SA_specs for weights</span></span>
<span><span class="va">l_weights</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>Address <span class="op">=</span> <span class="st">"$Log$Aggregate$w"</span>,</span>
<span>                  Distribution <span class="op">=</span> <span class="va">noisy_wts</span>,</span>
<span>                  Type <span class="op">=</span> <span class="st">"discrete"</span><span class="op">)</span></span></code></pre></div>
<p>Notice that the distribution is defined as discrete because in
practice we have 100 alternative sets of weights, even though we are
emulating a continuous distribution.</p>
<p>Last of all we define the list chunk for the aggregation method:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## aggregation</span></span>
<span><span class="va">l_agg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>Address <span class="op">=</span> <span class="st">"$Log$Aggregate$f_ag"</span>,</span>
<span>               Distribution <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"a_amean"</span>, <span class="st">"a_gmean"</span><span class="op">)</span>,</span>
<span>               Type <span class="op">=</span> <span class="st">"discrete"</span><span class="op">)</span></span></code></pre></div>
<p>This is relatively straightforward.</p>
<p>Having defined all of our input distributions individually, it’s time
to put them all together:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># create overall specification list</span></span>
<span><span class="va">SA_specs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  Winmax <span class="op">=</span> <span class="va">l_winmax</span>,</span>
<span>  Normalisation <span class="op">=</span> <span class="va">l_norm</span>,</span>
<span>  Weights <span class="op">=</span> <span class="va">l_weights</span>,</span>
<span>  Aggregation <span class="op">=</span> <span class="va">l_agg</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>We simply put our list chunks into a single list. The names of this
list are used as the names of the assumptions, so we can name them how
we want.</p>
</div>
<div class="section level2">
<h2 id="uncertainty-analysis">Uncertainty analysis<a class="anchor" aria-label="anchor" href="#uncertainty-analysis"></a>
</h2>
<p>That was all a bit complicated, but this is because defining a
sensitivity analysis <em>is</em> complicated! Now COINr can take over
from here. We can now call the <code><a href="../reference/get_sensitivity.html">get_sensitivity()</a></code>
function:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Not run here: will take a few seconds to finish if you run this</span></span>
<span><span class="va">SA_res</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_sensitivity.html">get_sensitivity</a></span><span class="op">(</span><span class="va">coin</span>, SA_specs <span class="op">=</span> <span class="va">SA_specs</span>, N <span class="op">=</span> <span class="fl">100</span>, SA_type <span class="op">=</span> <span class="st">"UA"</span>,</span>
<span>                          dset <span class="op">=</span> <span class="st">"Aggregated"</span>, iCode <span class="op">=</span> <span class="st">"Index"</span><span class="op">)</span></span></code></pre></div>
<p>This is not actually run when building this vignette because it can
take a little while to finish. When it is run you should get a message
saying that the weights address is not found or <code>NULL</code>. COINr
checks each address to see if there is already an object at that address
inside the coin. If there is not, or it is <code>NULL</code> it asks if
you want to continue anyway. In our case, the fact that it is
<code>NULL</code> is not because we made a mistake with the address, but
simply because the <code>w</code> argument of <code><a href="../reference/Aggregate.html">Aggregate()</a></code>
was not specified when we build the coin (i.e. it was set to
<code>NULL</code>), and the default “Original” weights were used.
Sometimes however, if an address is <code>NULL</code> it might be
because you have made an error.</p>
<p>Looking at the syntax of <code><a href="../reference/get_sensitivity.html">get_sensitivity()</a></code>: apart from
passing the coin and <code>SA_specs</code>, we also have to specify how
many replications to run (<code>N</code> - more replications results in
a more accurate sensitivity analysis, but also takes longer); whether to
run an uncertainty analysis (<code>SA_type = "UA"</code>) or a
sensitivity analysis (<code>SA_type = "SA"</code>); and finally the
<em>target</em> output of the sensitivity analysis, which in this case
we have specified as the Index, from the aggregated data set.</p>
<p>If the type of sensitivity analysis (<code>SA_type</code>) is set to
<code>"UA"</code>, assumptions will be sampled randomly and the results
will simply consist of the distribution over the ranks. This takes less
replications, and may be sufficient if you are just interested in the
output uncertainty, without attributing it to each input assumption. We
can directly look at the output uncertainty analysis by calling the
<code><a href="../reference/plot_uncertainty.html">plot_uncertainty()</a></code> function:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_uncertainty.html">plot_uncertainty</a></span><span class="op">(</span><span class="va">SA_res</span><span class="op">)</span></span></code></pre></div>
<p><img src="sensitivity_files/figure-html/unnamed-chunk-11-1.png" width="672"></p>
<p>Results are contained in the output of <code><a href="../reference/get_sensitivity.html">get_sensitivity()</a></code>
and can also be viewed directly, e.g.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">SA_res</span><span class="op">$</span><span class="va">RankStats</span><span class="op">)</span></span>
<span><span class="co">#&gt;   uCode Nominal  Mean Median    Q5 Q95</span></span>
<span><span class="co">#&gt; 1   AUS      35 35.28     35 34.00  38</span></span>
<span><span class="co">#&gt; 2   AUT       7  7.00      7  5.95   9</span></span>
<span><span class="co">#&gt; 3   BEL       5  5.15      5  3.00   9</span></span>
<span><span class="co">#&gt; 4   BGD      46 45.46     46 41.00  48</span></span>
<span><span class="co">#&gt; 5   BGR      30 27.59     28 24.00  30</span></span>
<span><span class="co">#&gt; 6   BRN      40 40.07     40 37.00  45</span></span></code></pre></div>
<p>This shows the nominal, mean, median, and 5th/95th percentile ranks
of each unit, as a result of the induced uncertainty.</p>
</div>
<div class="section level2">
<h2 id="sensitivity-analysis">Sensitivity analysis<a class="anchor" aria-label="anchor" href="#sensitivity-analysis"></a>
</h2>
<p>The process for performing a sensitivity analysis is the same, but we
set <code>SA_type = "SA"</code>.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Not run here: will take a few seconds to finish if you run this</span></span>
<span><span class="va">SA_res</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_sensitivity.html">get_sensitivity</a></span><span class="op">(</span><span class="va">coin</span>, SA_specs <span class="op">=</span> <span class="va">SA_specs</span>, N <span class="op">=</span> <span class="fl">100</span>, SA_type <span class="op">=</span> <span class="st">"SA"</span>,</span>
<span>                          dset <span class="op">=</span> <span class="st">"Aggregated"</span>, iCode <span class="op">=</span> <span class="st">"Index"</span>, Nboot <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span></code></pre></div>
<p>If you run this, you will see an important difference: although we
set <code>N = 100</code> the coin is replicated 600 times! This is
because a variance based sensitivity analysis requires a specific
<em>experimental design</em>, and the actual number of runs is <span class="math inline">\(N(d+2)\)</span>, where <span class="math inline">\(d\)</span> is the number of uncertain
assumptions.</p>
<p>Notice also that we have set <code>Nboot = 100</code>, which is the
number of bootstrap replications to perform, and is used for estimating
confidence intervals on sensitivity indices.</p>
<p>Let’s now plot the results using the <code><a href="../reference/plot_sensitivity.html">plot_sensitivity()</a></code>
function:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_sensitivity.html">plot_sensitivity</a></span><span class="op">(</span><span class="va">SA_res</span><span class="op">)</span></span></code></pre></div>
<p><img src="sensitivity_files/figure-html/unnamed-chunk-15-1.png" width="480"></p>
<p>By default this returns a bar chart. Each bar gives the sensitivity
of the results (in this case the average rank change of the Index
compared to nominal values) to each assumption. Clearly, the most
sensitive assumption is the aggregation method, and the least sensitive
is the maximum number of points to Winsorise.</p>
<p>The same results can be plotted as a pie chart, or as a box plot,
depending on how we set <code>ptype</code>:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_sensitivity.html">plot_sensitivity</a></span><span class="op">(</span><span class="va">SA_res</span>, ptype <span class="op">=</span> <span class="st">"box"</span><span class="op">)</span></span></code></pre></div>
<p><img src="sensitivity_files/figure-html/unnamed-chunk-16-1.png" width="672"></p>
<p>The confidence intervals are rather wide here, especially on the
first order sensitivity indices. By increasing <code>N</code>, the
precision of these estimates will increase and the confidence intervals
will narrow. In any case, the right hand plot (total order sensitivity
indices) is already clear: despite the estimation uncertainty, the order
of importance of the four assumptions is clearly distinguished.</p>
</div>
<div class="section level2">
<h2 id="discussiontips">Discussion/tips<a class="anchor" aria-label="anchor" href="#discussiontips"></a>
</h2>
<p>The <code><a href="../reference/get_sensitivity.html">get_sensitivity()</a></code> function is very flexible because
it can target anything inside the coin. However, this comes at the
expense of carefully specifying the uncertainties in the analysis, and
having a general understanding of how a coin is regenerated. For this
latter part, it may also help to read the <a href="adjustments.html">Adjustments and comparisons</a> vignette.</p>
<p>Some particular points to consider:</p>
<ul>
<li>It is your responsibility to get the correct address for each
parameter and to understand its use.</li>
<li>It is also your responsibility to make sure that there are no
conflicts caused by methodological variations, such as negative values
being fed into a geometric mean.</li>
<li>You can’t target the same parameter twice in the same sensitivity
analysis - one specification will just overwrite the other.</li>
</ul>
<p>In general it is better to start simple: start with one or two
assumptions to vary and gradually expand the level of complexity as
needed. You can also do a test run with a low <code>N</code> to see if
the results are vaguely sensible.</p>
<p>Variance based sensitivity analysis is complicated, especially here
because the assumptions to vary are often not just a single value, but
could be strings, data frames or lists. Again, an understanding of COINr
and a basic understanding of sensitivity analysis can help a lot.</p>
<p>One important point is that in a sensitivity analysis, the target of
the sensitivity analysis is the <em>mean absolute rank change</em>.
COINr takes the target output that you specify, and for each replication
compares the ranks of that variable to the nominal ranks. It then takes
the difference between these two and takes the mean absolute value of
these differences: the higher value of this quantity, the more the ranks
have changed with respect to the nominal. This is done because
variance-based SA generally requires a univariate output.</p>
<p>If you want to perform a more complex sensitivity analysis, perhaps
generating separate sensitivity indices for each unit, you could also do
this by bypassing <code><a href="../reference/get_sensitivity.html">get_sensitivity()</a></code> altogether. If you want
to venture down this path, check out <code><a href="../reference/SA_sample.html">SA_sample()</a></code> and
<code><a href="../reference/SA_estimate.html">SA_estimate()</a></code>, which are called by
<code><a href="../reference/get_sensitivity.html">get_sensitivity()</a></code>. This would definitely require some
custom coding on your part but if you feel up for the challenge, go for
it!</p>
</div>
<div class="section level2">
<h2 id="removing-elements">Removing elements<a class="anchor" aria-label="anchor" href="#removing-elements"></a>
</h2>
<p>Last of all we turn to a separate function which is not
variance-based sensitivity analysis but is related to sensitivity
analysis in general. The <code><a href="../reference/remove_elements.html">remove_elements()</a></code> function tests
the effect of removing components of the composite indicator one at a
time. This can be useful to find the impact of each component, in terms
of “if it I were to remove this, what would happen?”.</p>
<p>To run this, we input our coin into the function and specify which
level we want to remove components. For example, specifying
<code>Level = 2</code> removes each component of level 2 one at a time,
with replacement, and regenerates the results each time. We also have to
specify which indicator/aggregate to target as the output:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># run function removing elements in level 2</span></span>
<span><span class="va">l_res</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/remove_elements.html">remove_elements</a></span><span class="op">(</span><span class="va">coin</span>, Level <span class="op">=</span> <span class="fl">2</span>, dset <span class="op">=</span> <span class="st">"Aggregated"</span>, iCode <span class="op">=</span> <span class="st">"Index"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Iteration 1 of 8</span></span>
<span><span class="co">#&gt; Iteration 2 of 8</span></span>
<span><span class="co">#&gt; Iteration 3 of 8</span></span>
<span><span class="co">#&gt; Iteration 4 of 8</span></span>
<span><span class="co">#&gt; Iteration 5 of 8</span></span>
<span><span class="co">#&gt; Iteration 6 of 8</span></span>
<span><span class="co">#&gt; Iteration 7 of 8</span></span>
<span><span class="co">#&gt; Iteration 8 of 8</span></span>
<span></span>
<span><span class="co"># get summary of rank changes</span></span>
<span><span class="va">l_res</span><span class="op">$</span><span class="va">MeanAbsDiff</span></span>
<span><span class="co">#&gt;   Nominal  Physical  ConEcFin Political    Instit       P2P   Environ    Social </span></span>
<span><span class="co">#&gt;  0.000000  1.529412  2.627451  2.901961  1.176471  1.686275  3.098039  3.960784 </span></span>
<span><span class="co">#&gt;  SusEcFin </span></span>
<span><span class="co">#&gt;  2.627451</span></span></code></pre></div>
<p>The output contains details of ranks and scores, but the
“MeanAbsDiff” entry is a good summary: it shows the mean absolute rank
difference between nominal ranks, and ranks with each component removed.
Here, a higher value means that the ranks are changed more when that
component is removed and vice versa. Clearly, the impact of removing
components is not the same, and this can be useful information if you
are considering whether or not to discard part of an index.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by William Becker.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.6.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
